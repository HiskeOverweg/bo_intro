{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bo_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIuOj5jZPivhi6XRhV9RxB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HiskeOverweg/bo_intro/blob/master/bo_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyEAowGDYVhZ",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Bayesian optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch2mCpaqYLAR",
        "colab_type": "code",
        "outputId": "3dab077e-713d-4f09-eb0f-08823ef27a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "!pip install git+https://github.com/HiskeOverweg/bo_intro.git --upgrade\n",
        "!pip install botorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/HiskeOverweg/bo_intro.git\n",
            "  Cloning https://github.com/HiskeOverweg/bo_intro.git to /tmp/pip-req-build-3ttw1ky2\n",
            "  Running command git clone -q https://github.com/HiskeOverweg/bo_intro.git /tmp/pip-req-build-3ttw1ky2\n",
            "Building wheels for collected packages: bo-intro\n",
            "  Building wheel for bo-intro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bo-intro: filename=bo_intro-0.1-cp36-none-any.whl size=3025 sha256=4eb4cab1e6ae10948369cd85d581c9291144bcf9b276b349b505f3342b295cc5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vnmox674/wheels/ba/76/c2/d1418048f26d6e4a8f33ccb92738e0d12c26f27fcb4bdcc822\n",
            "Successfully built bo-intro\n",
            "Installing collected packages: bo-intro\n",
            "  Found existing installation: bo-intro 0.1\n",
            "    Uninstalling bo-intro-0.1:\n",
            "      Successfully uninstalled bo-intro-0.1\n",
            "Successfully installed bo-intro-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "bo_intro"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: botorch in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from botorch) (1.4.0)\n",
            "Requirement already satisfied: gpytorch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from botorch) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from botorch) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->botorch) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bbh74XxYLuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from bo_intro.run_bayesian_optimization import run_bo_experiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPA3snApYmFT",
        "colab_type": "text"
      },
      "source": [
        "## Torch tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzwGRlMnZLPe",
        "colab_type": "text"
      },
      "source": [
        "In some of the code we use below you'll see [Pytorch tensors](https://pytorch.org/tutorials/beginner/former_torchies/tensor_tutorial.html). You can think of them as numpy arrays with some extra functionality. You can convert as follows:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWnUkhhLYfoO",
        "colab_type": "code",
        "outputId": "15fe7e65-aba3-4634-b7e9-3160bb929b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "my_tensor = torch.tensor([0., 1., 2.], dtype=torch.double)\n",
        "my_numpy_array = my_tensor.numpy()\n",
        "print('We converted the tensor to the following type:')\n",
        "print(type(my_numpy_array))\n",
        "\n",
        "new_tensor = torch.from_numpy(my_numpy_array)\n",
        "print('We converted the numpy array to the following type:')\n",
        "print(type(new_tensor))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We converted the tensor to the following type:\n",
            "<class 'numpy.ndarray'>\n",
            "We converted the numpy array to the following type:\n",
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xuzbPuebZth",
        "colab_type": "text"
      },
      "source": [
        "## The sine dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpKtYsZgbe9r",
        "colab_type": "text"
      },
      "source": [
        "Below we see our first example of a dataset class for Bayesian optimization. The different functions will be explained below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqNgeloPYNz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sine:\n",
        "    def __init__(self, config={}):\n",
        "        bounds = torch.tensor([[0, 2*np.pi]], dtype=torch.double)\n",
        "        self.min, _ = torch.min(bounds, dim=1, keepdim=True)\n",
        "        self.min = torch.transpose(self.min, 0, 1)\n",
        "        self.interval = torch.abs(bounds[:, 0] - bounds[:, 1])\n",
        "        self.noise = config.setdefault('noise', 0)\n",
        "        self.dim = bounds.shape[0]\n",
        "        self.num_points = config.setdefault('initial_observations', 0)\n",
        "        self.x = torch.rand(self.num_points, self.dim, dtype=torch.double)\n",
        "        self.y = self.query(self.x)\n",
        "        self.max = 1\n",
        "\n",
        "    def query(self, x):\n",
        "        x_rescaled = self.rescale(x)\n",
        "        y = torch.sin(x_rescaled)\n",
        "        y = self.add_noise(y)\n",
        "        return y\n",
        "        \n",
        "    def add(self, new_x, new_y):\n",
        "        self.x = torch.cat([self.x, new_x])\n",
        "        self.y = torch.cat([self.y, new_y])\n",
        "\n",
        "    def add_noise(self, y):\n",
        "        if self.noise > 0:\n",
        "            y += torch.randn(y.size(), dtype=torch.double) * self.noise\n",
        "        if y.dim()==1:\n",
        "            y = y.unsqueeze(1)\n",
        "        return y\n",
        "\n",
        "    def scale(self, x):\n",
        "        \"\"\"\n",
        "        scale from real world interval to unit cube\n",
        "        \"\"\"\n",
        "        x_scaled = (x - self.min)/self.interval\n",
        "        return x_scaled\n",
        "\n",
        "    def rescale(self, x):\n",
        "        \"\"\"\n",
        "        scale unit cube to real world interval\n",
        "        \"\"\"\n",
        "        x_rescaled = x * self.interval + self.min\n",
        "        return x_rescaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng2eNO96cX-1",
        "colab_type": "text"
      },
      "source": [
        "We can create an instance of this class as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "docM55lrcXCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Sine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWUQzbAscyqS",
        "colab_type": "text"
      },
      "source": [
        "The starting point and length of the interval over which the optimization is performed are given by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eMXgZwgcqMU",
        "colab_type": "code",
        "outputId": "30dc3e26-cf57-4877-b534-d82751f47998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(f\"starting point of the interval: {dataset.min}\")\n",
        "print(f\"length of the interval: {dataset.interval}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting point of the interval: tensor([[0.]], dtype=torch.float64)\n",
            "length of the interval: tensor([6.2832], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LYW5JHph9ia",
        "colab_type": "text"
      },
      "source": [
        "When performing Bayesian optimization, it is advisable to scale your data to the unit cube. For convenience, I implemented the scale function, which scales data to the unit cube."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ctoU1zc44m",
        "colab_type": "code",
        "outputId": "d7b03669-8e87-46ba-e54e-353228e3868f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "x_values = torch.from_numpy(np.linspace(0, 2*np.pi, 10))\n",
        "print('x values: ', x_values)\n",
        "scaled_values = dataset.scale(x_values)\n",
        "print('scaled x values: ', scaled_values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x values:  tensor([0.0000, 0.6981, 1.3963, 2.0944, 2.7925, 3.4907, 4.1888, 4.8869, 5.5851,\n",
            "        6.2832], dtype=torch.float64)\n",
            "scaled x values:  tensor([[0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "         1.0000]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spdgT_yfkKci",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 1** Check that the rescaling function does what you expect it to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkTZtdKjkIYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enoCj66GkucD",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 2** Use the query function to plot the sine function between 0 and 2$\\pi$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykv2QnOSf9i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_flOrPJfCcJ",
        "colab_type": "text"
      },
      "source": [
        "##Finding the maximum of the sine function\n",
        "\n",
        "We can run Bayesian optimization with 2 random starting points an 20 iterations on the sine function as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOTrjZtRkt0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#insert code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4p8ZK7MfU60",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 3** Plot a sine function and the datapoints x, y queried by the Bayesian optimization algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY3U3rMXfRaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2E9qm8QuYfM",
        "colab_type": "text"
      },
      "source": [
        "Let's fit a Gaussian process to the complete dataset. We can plot it's mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5cS0-tguXWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# insert some code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikoZlMgfgOMA",
        "colab_type": "text"
      },
      "source": [
        "**Exercise 5** Try adding some noise to the observations by adding the key 'noise' to the config dictionary. The corresponding value is the standard deviation of the Gaussian distributed noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7d7Ca5KnN-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9Gee2BLglhd",
        "colab_type": "text"
      },
      "source": [
        "##Regret\n",
        "\n",
        "The regret is defined as the difference between the true maximum of the function and the best value found so far.\n",
        "\n",
        "**Exercise 6** Plot the regret as a function of iteration number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT0LbC20fwoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add first line here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXd2IyyQh6-0",
        "colab_type": "text"
      },
      "source": [
        "Since Bayesian optimization is a stochastic algorithm it can be useful to evaluate the regret over a few different initializations of the algorithm.\n",
        "\n",
        "**Exercise 7** Run the algorithm 5 times with different random seeds and make a plot of the regret as a function of iteration number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BddupzBGB2cA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd2PN-rnipUE",
        "colab_type": "text"
      },
      "source": [
        "##Comparing acquisition functions\n",
        "\n",
        "Let us now compare a few acquisition functions. You can specify the key 'acquisition_function' in the config dictionary to switch to 'random' or 'ucb' (Upper Confidence Bound) rather than the default option 'ei' (Expected Improvement)\n",
        "\n",
        "**Exercise 8** Repeat exercise 6 with a random acquisition function. Which acquisition function leads to the lowest regret?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXjrj8vQFklY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3lmGYd9imoi",
        "colab_type": "text"
      },
      "source": [
        "## Optimizing a 2-dimensional function\n",
        "\n",
        "**Exercise 9** Try optimizing the [negative Branin function](https://www.sfu.ca/~ssurjano/branin.html) by specifying 'dataset':'branin' in the config dictionary. Make a plot of regret vs iteration number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByF4m2L_HLlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV0CUgfdk4F8",
        "colab_type": "text"
      },
      "source": [
        "## Template for optimization of measurement in Labber\n",
        "\n",
        "A dataset which would perform an experiment in Labber to acquire new datapoints would roughly look like (see also [Labber documentation about scripting](http://labber.org/online-doc/api/ScriptTools.html/)): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPQuR1qvk_lS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from Labber import ScriptTools\n",
        "\n",
        "class LabberExperiment(Sine):\n",
        "    def __init__(self, config={}):\n",
        "        bounds = torch.tensor([[0, 1]], dtype=torch.double)\n",
        "        self.min, _ = torch.min(bounds, dim=1, keepdim=True)\n",
        "        self.min = torch.transpose(self.min, 0, 1)\n",
        "        self.interval = torch.abs(bounds[:, 0] - bounds[:, 1])\n",
        "        self.dim = bounds.shape[0]\n",
        "        self.num_points = config.setdefault('initial_observations', 0)\n",
        "        self.x = torch.rand(self.num_points, self.dim, dtype=torch.double)\n",
        "        self.y = self.query(self.x)\n",
        "        # define measurement objects\n",
        "        sPath = os.path.dirname(os.path.abspath(__file__))\n",
        "        self.MeasResonator = ScriptTools.MeasurementObject(\\\n",
        "                os.path.join(sPath, 'TestResonator.hdf5'),\n",
        "                os.path.join(sPath, 'TestResonatorOut.hdf5'))\n",
        "        self.MeasResonator.setMasterChannel('Flux bias')\n",
        "\n",
        "    def query(self, x):\n",
        "        x_rescaled = self.rescale(x)\n",
        "        results = []\n",
        "        for setting in x:\n",
        "          self.MeasResonator.updateValue('Flux bias', setting.numpy())\n",
        "          (x,y) = self.MeasResonator.performMeasurement()\n",
        "          results.append(y)\n",
        "        return torch.tensor(results, dtype=torch.double).unsqueeze(dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXZf0HetopU4",
        "colab_type": "text"
      },
      "source": [
        "##Batch mode Bayesian optimization\n",
        "\n",
        "It is also possible to run Bayesian optimization in batch mode: rather than querying for the next most informative datapoint, we can ask for a batch of N most informative datapoints. This can be especially useful in a simulation, where you can evaluate multiple settings in parallel. More details about batch mode can be found [here](https://botorch.org/docs/batching#docsNav).\n",
        "\n",
        "##Conclusion\n",
        "\n",
        "I hope this intro helped to get a basic understanding of Bayesian optimization. If you come up with a way to use it in your own experiments, please let me know, I am curious to hear about it!"
      ]
    }
  ]
}